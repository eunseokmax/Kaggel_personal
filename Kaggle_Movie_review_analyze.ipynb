{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words Meets Bags of Popcorn\n",
    "\n",
    "- <https://www.kaggle.com/c/word2vec-nlp-tutorial/data>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 자연 언어 처리 - 위키백과, 우리모두의 백과사전\n",
    " - 자연어 처리는 인간이 발화하는 언어현상을 기계적으로 분석해서 컴퓨터가 이해할 수 있는 형태로 만드는 자연 언어 이해 또는 그러한 형태를 다시 인간이 이해할 수 있는 언어로 표현하는 제반 기술을 의미 (출처 : 위키피디아)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파트 1\n",
    " - 초보자를 대상으로 기본 자연어 처리를 다룬다.\n",
    " \n",
    "### 파트 2, 3\n",
    " - word2vec을 사용하여 모델을 학습시키는 방법과 감정분석에 단어 벡터를 사용하는 방법을 본다.\n",
    " - 파트 3에서는 레시피를 제공하지 않고 word2vec을 사용하는 몇 가지 방법을 실험.\n",
    " - K-means 알고리즘을 사용해 군집화 해본다.\n",
    " - 긍정/부정 리뷰가 섞여 있는 100000만 개의 IMDB 감정분석 데이터 세트를 통해 목표를 달성해 본다.\n",
    " \n",
    " ### BOW(bag of words)\n",
    " - 가장 간단하지만, 효과적이라 널리 쓰이는 방법\n",
    " - 장, 문단, 문장, 서식과 같은 입력 텍스트의 구조를 제외하고 각 단어가 이 말뭉치에 얼마나 많이 나타나는지만 헤아린다.\n",
    " - 구조와 상관없이 단어의 출현횟수만 세기 때문에 텍스트를 담는 가방(bag)으로 생각할 수 있다. \n",
    " - BOW는 단어의 순서가 완전히 무시 된다는 단점. \n",
    "   > - it's bad, not good at all.\n",
    "   > - It's good, not bad at all.\n",
    " - 위 두문장은 의미가 전혀 반대지만 완전히 동일하게 반환된다.\n",
    " * 이를 보완하기 위해 n-gram을 사용하는데 BOW는 하나의 토큰을 사용하지만, n-gram은 n개의 토큰을 사용할 수 있도록 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시작하기 전에\n",
    " NLP 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 3)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "header = 0 은 파일의 첫 번째 줄에 열 이름이 있음을 나타내며\n",
    "delimiter = \\t 는 필드가 탭으로 구분되는 것을 의미\n",
    "quoting = 3은 큰 따옴표를 무시하도록 한다.\n",
    "\"\"\"\n",
    "\n",
    "# quote_minimal (0), qoute_all(1), quote_nonnumeric(2) or quote_none (3).\n",
    "\n",
    "#레이블인 sentiment가 있는 학습 데이터\n",
    "train = pd.read_csv(\"C://BigData/Kaggle/BoWMBoP/labeledTrainData.tsv\", header=0, delimiter='\\t',quoting=3)\n",
    "\n",
    "#레이블이 없는 테스터 데이터\n",
    "test = pd.read_csv(\"C://BigData/Kaggle/BoWMBoP/testData.tsv\", header=0, delimiter='\\t', quoting=3)\n",
    "\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"12311_10\"</td>\n",
       "      <td>\"Naturally in a film who's main themes are of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"8348_2\"</td>\n",
       "      <td>\"This movie is a disaster within a disaster fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"5828_4\"</td>\n",
       "      <td>\"All in all, this is a movie for kids. We saw ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"7186_2\"</td>\n",
       "      <td>\"Afraid of the Dark left me with the impressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"12128_7\"</td>\n",
       "      <td>\"A very accurate depiction of small time mob l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                             review\n",
       "0  \"12311_10\"  \"Naturally in a film who's main themes are of ...\n",
       "1    \"8348_2\"  \"This movie is a disaster within a disaster fi...\n",
       "2    \"5828_4\"  \"All in all, this is a movie for kids. We saw ...\n",
       "3    \"7186_2\"  \"Afraid of the Dark left me with the impressio...\n",
       "4   \"12128_7\"  \"A very accurate depiction of small time mob l..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'sentiment', 'review'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'review'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns.values #레이블인 'sentiment'가 없다. 이 데이터를 기계학습을 통해 예측한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 3 columns):\n",
      "id           25000 non-null object\n",
      "sentiment    25000 non-null int64\n",
      "review       25000 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 586.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.50001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment\n",
       "count  25000.00000\n",
       "mean       0.50000\n",
       "std        0.50001\n",
       "min        0.00000\n",
       "25%        0.00000\n",
       "50%        0.50000\n",
       "75%        1.00000\n",
       "max        1.00000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12500\n",
       "0    12500\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ\\'s feeling towards the press and also the obvious message of drugs are bad m\\'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely lik'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# html 태그가 섞여 있기 때문에 이를 정제해줄 필요가 있음\n",
    "train['review'][0][:700]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP 텍스트 데이터 전처리\n",
    "### 데이터 정제 Data Cleaning and Text Preprocessing\n",
    "\n",
    " 기계가 텍스트를 이해할 수 있도록 텍스트를 정제해 준다.\n",
    "  1. BeautifulSoup을 통해 HTML 태그를 제거\n",
    "  2. 정규표현식으로 알파벳 이외의 문자를 공백으로 치환\n",
    "  3. NLTK데이터를 사용해 불용어(Stopword)를 제거\n",
    "  4. 어간추출(스테밍 Stemming)과 음소표기법(Lemmatizing)의 개념을 이해하고 SnowballStemmer를 통해 어간을 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 데이터 전처리 이해하기\n",
    "\n",
    "#### 정규화 normalization\n",
    " * 한국어를 처리하는 예시입니닼ㅋㅋㅋㅋㅋ -> 한국어를 처리하는 예시입니다. ㅋㅋ\n",
    " \n",
    "#### 토큰화 tokenization\n",
    " * 한국어를 처리하는 예시입니다. ㅋㅋ -> 한국어 Noun, 를 Josa, 처리 Noun\n",
    " \n",
    "#### 어근화 stemming\n",
    " * 한국어를 처리하는 예시입니다 ㅋㅋ -> 한국어Noun, 를Josa, 처리Noun, 하다Verb, 예시Noun, 이다Adjective, ㅋㅋKoreanParticle\n",
    " \n",
    "#### 어구 추출 phrase extraction\n",
    " * 한국어를 처리하는 예시입니다 ㅋㅋ -> 한국어, 처리, 예시, 처리하는 예시\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: beautifulsoup4\n",
      "Version: 4.6.3\n",
      "Summary: Screen-scraping library\n",
      "Home-page: http://www.crummy.com/software/BeautifulSoup/bs4/\n",
      "Author: Leonard Richardson\n",
      "Author-email: leonardr@segfault.org\n",
      "License: MIT\n",
      "Location: c:\\anaconda3\\lib\\site-packages\n",
      "Requires: \n",
      "Required-by: conda-build\n"
     ]
    }
   ],
   "source": [
    "!pip show BeautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely lik\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ\\'s feeling towards the press and also the obvious message of drugs are bad m\\'kay.Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyw'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "example1 = BeautifulSoup(train['review'][0], \"html5lib\")\n",
    "print(train['review'][0][:700])\n",
    "example1.get_text()[:700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' With all this stuff going down at the moment with MJ i ve started listening to his music  watching the odd documentary here and there  watched The Wiz and watched Moonwalker again  Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent  Moonwalker is part biography  part feature film which i remember going to see at the cinema when it was originally released  Some of it has subtle messages about MJ s feeling towards the press and also the obvious message of drugs are bad m kay Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyw'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정규표현식을 사용해서 특수문자를 제거\n",
    "import re\n",
    "# 소문자와 대문자가 아닌 것은 공백으로 대체\n",
    "letters_only = re.sub('[^a-zA-z]',' ', example1.get_text())\n",
    "letters_only[:700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['with',\n",
       " 'all',\n",
       " 'this',\n",
       " 'stuff',\n",
       " 'going',\n",
       " 'down',\n",
       " 'at',\n",
       " 'the',\n",
       " 'moment',\n",
       " 'with']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모두 소문자로 변화\n",
    "lower_case = letters_only.lower()\n",
    "# 문자를 나눈다. -> 토큰화\n",
    "words = lower_case.split()\n",
    "print(len(words))\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 불용어 제거(Stopword Removal)\n",
    "\n",
    "일반적으로 코퍼스에서 자주 나타나는 단어는 학습 모델로서 학습이나 예측 프로세스에 실제로 기여하지 않아 다른 텍스트와 구별하지 못한다. 예를들어 조사, 접미사 등과 같은 단어는 빈번하게 등장하지만, 실제 의미를 찾는데 크게 기여하지 않는다 .Stopwords는 to또는 the와 같은 용어를 포함하므로 사전 처리 단계에서 제거하는 것이 좋다. NLTK에는 153개의 영어 불용어가 미리 정의되어 있다. 17개의 언어에 대해 정의되어 있으며 한국어는 없다. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['stuff',\n",
       " 'going',\n",
       " 'moment',\n",
       " 'mj',\n",
       " 'started',\n",
       " 'listening',\n",
       " 'music',\n",
       " 'watching',\n",
       " 'odd',\n",
       " 'documentary']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stopwords 를 제거한 토큰들\n",
    "words = [w for w in words if not w in stopwords.words('english')]\n",
    "print(len(words))\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 스테밍(어간추출, 형태소 분석)\n",
    "\n",
    "출처 : [어간추출 - 위키백과](https://ko.wikipedia.org/wiki/%EC%96%B4%EA%B0%84_%EC%B6%94%EC%B6%9C)\n",
    "\n",
    " * 어간 추출(語幹 抽出, 영어: stemming)은 어형이 변형된 단어로부터 접사 등을 제거하고 그 단어의 어간을 분리해 내는 것\n",
    " * message, messages, messaging과 같이 복수형, 진행형 등의 문자를 같은 의미의 단어로 다룰 수 있도록 도와준다.\n",
    " * stemming(형태소 분석): 여기에서는 NLTK에서 제공하는 형태소 분석기를 사용한다. 포터 형태소 분석기는 보수적이고 랭커스터 형태소 분석기는 좀 더 적극적이다. 형태소 분석 규칙의 적극성 때문에 랭커스터 형태소 분석기는 더 많은 동음이의어 형태소를 생산한다. [참고 : 모두의 데이터 과학 with 파이썬(길벗)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum\n",
      "The stemmed fom of running is : run\n",
      "The stemmed fom of runs is : run\n",
      "The stemmed fom of run is : run\n"
     ]
    }
   ],
   "source": [
    "# 포터 스태머의 사용 예\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "print(stemmer.stem('maximum'))\n",
    "print('The stemmed fom of running is : {}'.format(stemmer.stem('running')))\n",
    "print('The stemmed fom of runs is : {}'.format(stemmer.stem('runs')))\n",
    "print('The stemmed fom of run is : {}'.format(stemmer.stem('run')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxim\n",
      "The stemmed fom of running is : run\n",
      "The stemmed fom of runs is : run\n",
      "The stemmed fom of run is : run\n"
     ]
    }
   ],
   "source": [
    "# 랭커스터 스태머의 사용 예\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "print(lancaster_stemmer.stem('maximum'))\n",
    "print('The stemmed fom of running is : {}'.format(lancaster_stemmer.stem('running')))\n",
    "print('The stemmed fom of runs is : {}'.format(lancaster_stemmer.stem('runs')))\n",
    "print('The stemmed fom of run is : {}'.format(lancaster_stemmer.stem('run')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['stuff',\n",
       " 'going',\n",
       " 'moment',\n",
       " 'mj',\n",
       " 'started',\n",
       " 'listening',\n",
       " 'music',\n",
       " 'watching',\n",
       " 'odd',\n",
       " 'documentary']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 처리 전 단어\n",
    "print(len(words))\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['stuff',\n",
       " 'go',\n",
       " 'moment',\n",
       " 'mj',\n",
       " 'start',\n",
       " 'listen',\n",
       " 'music',\n",
       " 'watch',\n",
       " 'odd',\n",
       " 'documentari']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "words = [stemmer.stem(w) for w in words]\n",
    "# 처리 후 단어\n",
    "print(len(words))\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization 음소표기법\n",
    "\n",
    "언어학에서 음소표기법은 단어의 보조 정리 또는 사전 형식에 의해 식별되는 단일 항목으로 분석될 수 있도록 굴절된 형태의 단어를 그룹화하는 과정. 예를 들어 동음이의어가 문맥에 따라 다른 의미가 있는데 \n",
    "\n",
    " 1) 배가 맛있다.\n",
    " 2) 배를 타는 것이 재미있다.\n",
    " 3) 평소보다 두 배로 많이 먹어서 배가 아프다.\n",
    " \n",
    "위에 있는 3개의 문장에 있는 \"배\"는 모두 다른 의미가 있다.\n",
    "\n",
    "레마타이제이션은 이때 앞뒤 문맥을 보고 단어의 의미를 식별하는 것이다. 영어에서 meet는 meeting으로 쓰였을 때 회의를 뜻하지만, meet일 때는 만나다는 뜻을 갖는데 그 단어가 명사로 쓰였는지 동사로 쓰였는지에 따라 적합한 의미가 있도록 추출하는 것이다. \n",
    "\n",
    " * 참고 \n",
    "  > * [Stemming and lemmatization](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html)\n",
    "  > * [Lemmatisation - Wikipedia](https://en.wikipedia.org/wiki/Lemmatisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_words( raw_review ):\n",
    "    # 1. HTML 제거\n",
    "    review_text = BeautifulSoup(raw_review, 'html.parser').get_text()\n",
    "    # 2. 영문자가 아닌 문자는 공백으로 변환\n",
    "    letters_only = re.sub('[^a-zA-Z]', ' ', review_text)\n",
    "    # 3. 소문자 변환\n",
    "    words = letters_only.lower().split()\n",
    "    # 4. 파이썬에서는 리스트보다 세트로 찾는 게 훨씬 빠르다.\n",
    "    # stopwords 를 세트로 변환한다.\n",
    "    stops = set(stopwords.words('english'))\n",
    "    # 5. Stopwords 불용어 제거\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    # 6. 어간추출\n",
    "    stemming_words = [stemmer.stem(w) for w in meaningful_words]\n",
    "    # 7. 공백으로 구분된 문자열로 결합하여 결과를 반환\n",
    "    return( ' '.join(stemming_words) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stuff go moment mj start listen music watch odd documentari watch wiz watch moonwalk mayb want get certain insight guy thought realli cool eighti mayb make mind whether guilti innoc moonwalk part biographi part featur film rememb go see cinema origin releas subtl messag mj feel toward press also obvious messag drug bad kay visual impress cours michael jackson unless remot like mj anyway go hate find bore may call mj egotist consent make movi mj fan would say made fan true realli nice actual featur film bit final start minut exclud smooth crimin sequenc joe pesci convinc psychopath power drug lord want mj dead bad beyond mj overheard plan nah joe pesci charact rant want peopl know suppli drug etc dunno mayb hate mj music lot cool thing like mj turn car robot whole speed demon sequenc also director must patienc saint came film kiddi bad sequenc usual director hate work one kid let alon whole bunch perform complex danc scene bottom line movi peopl like mj one level anoth think peopl stay away tri give wholesom messag iron mj bestest buddi movi girl michael jackson truli one talent peopl ever grace planet guilti well attent gave subject hmmm well know peopl differ behind close door know fact either extrem nice stupid guy one sickest liar hope latter'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_review = review_to_words(train['review'][0])\n",
    "clean_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 번째 리뷰를 대상으로 전처리해줬던 내용을 전체 텍스트 데이터를 대상으로 처리한다.\n",
    "# 전체 리뷰 데이터 수 가져오기\n",
    "num_reviews = train['review'].size\n",
    "num_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n코드는 한 줄로 간결해졌지만 여전히 오래 걸림\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "clean_train_reviews = []\n",
    "캐글 튜토리얼에는 range가 xrange로 되어있지만 \n",
    "여기에서는 python3를 사용하기 때문에 range를 사용했다.\n",
    "\"\"\"\n",
    "# for i in range(0, num_reviews):\n",
    "#     clean_train_reviews.append( review_to_words(train['review'][i]))\n",
    "\"\"\"\n",
    "하지만 위 코드는 어느 정도 실행이 되고 있는지 알 수가 없어서\n",
    "5000개 단위로 상태를 찍도록 개선했다.\n",
    "\"\"\"\n",
    "# clean_train_reviews = []\n",
    "# for i in range(0, num_reviews):\n",
    "#     if (i + 1)%5000 == 0:\n",
    "#         print('Review {} of {} '.format(i+1, num_reviews))\n",
    "#     clean_train_reviews.append(review_to_words(train['review'][i]))\n",
    "\n",
    "\"\"\"\n",
    "그리고 코드를 좀 더 간결하게 하려고 for loop를 사용하는\n",
    "대신 apply를 사용하도록 개선\n",
    "\"\"\"\n",
    "# %time train['review_clean'] = train['review'].apply(review_to_words)\n",
    "\"\"\"\n",
    "코드는 한 줄로 간결해졌지만 여전히 오래 걸림\n",
    "\"\"\"\n",
    "# CPU times: user 1min 15s, sys: 2.3 s, total: 1min 18s\n",
    "# Wall time: 1min 20s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 참고 : https://gist.github.com/yong27/7869662\n",
    "# http://www.racketracer.com/2016/07/06/pandas-in-parallel/\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "\n",
    "def _apply_df(args):\n",
    "    df, func, kwargs = args\n",
    "    return df.apply(func, **kwargs)\n",
    "\n",
    "def apply_by_multiprocessing(df, func, **kwargs):\n",
    "    # 키워드 항목 중 workers 파라메터를 꺼냄\n",
    "    workers = kwargs.pop('workers')\n",
    "    # 위에서 가져온 workers 수로 프로세스 풀을 정의\n",
    "    pool = Pool(processes=workers)\n",
    "    # 실행할 함수와 데이터프레임을 워커의 수 만큼 나눠 작업\n",
    "    result = pool.map(_apply_df, [(d, func, kwargs)\n",
    "            for d in np.array_split(df, workers)])\n",
    "    pool.close()\n",
    "    # 작업 결과를 합쳐서 반환\n",
    "    return pd.concat(list(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time clean_train_reviews = apply_by_multiprocessing(\\\n",
    "    train['review'], review_to_words, workers=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time clean_test_reviews = apply_by_multiprocessing(\\\n",
    "    test['review'], review_to_words, workers=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
